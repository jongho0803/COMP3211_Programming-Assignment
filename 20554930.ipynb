{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to format inputs to ChatGPT models\n",
        "\n",
        "ChatGPT is powered by `gpt-3.5-turbo`.\n",
        "\n",
        "You can build your own applications with `gpt-3.5-turbo` using the OpenAI API.\n",
        "\n",
        "Chat models take a series of messages as input, and return an AI-written message as output.\n",
        "\n",
        "This guide illustrates the chat format with a few example API calls."
      ],
      "metadata": {
        "id": "qqjZqQDHKa4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import the openai library"
      ],
      "metadata": {
        "id": "Gw3uhwvJKuo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "XCuENuJ-GYkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fc75d0-9b10-42d8-a21e-4f8f04a7394a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QJjuwqVDd_Wi"
      },
      "outputs": [],
      "source": [
        "# import the OpenAI Python library for calling the OpenAI API\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. An example chat API call\n",
        "\n",
        "A chat API call has two required inputs:\n",
        "- `model`: the name of the model you want to use (e.g., `gpt-3.5-turbo`)\n",
        "- `messages`: a list of message objects, where each object has at least two fields:\n",
        "    - `role`: the role of the messenger (either `system`, `user`, or `assistant`)\n",
        "    - `content`: the content of the message (e.g., `Write me a beautiful poem`)\n",
        "\n",
        "Typically, a conversation will start with a system message, followed by alternating user and assistant messages, but you are not required to follow this format.\n",
        "\n",
        "Let's look at an example chat API calls to see how the chat format works in practice."
      ],
      "metadata": {
        "id": "0ldE8pkOKxUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title openai.api_key\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "k28l6lCmGg05",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example OpenAI Python library request\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "nUuaJaXLK4Pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095e8b97-2f34-4678-c5e8-970454ed370b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-78v2K5WxPFs1n5goyReDyqh2dsH9W at 0x7f128eb29e00> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"Orange who?\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1682360228,\n",
              "  \"id\": \"chatcmpl-78v2K5WxPFs1n5goyReDyqh2dsH9W\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 3,\n",
              "    \"prompt_tokens\": 39,\n",
              "    \"total_tokens\": 42\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the response object has a few fields:\n",
        "- `id`: the ID of the request\n",
        "- `object`: the type of object returned (e.g., `chat.completion`)\n",
        "- `created`: the timestamp of the request\n",
        "- `model`: the full name of the model used to generate the response\n",
        "- `usage`: the number of tokens used to generate the replies, counting prompt, completion, and total\n",
        "- `choices`: a list of completion objects (only one, unless you set `n` greater than 1)\n",
        "    - `message`: the message object generated by the model, with `role` and `content`\n",
        "    - `finish_reason`: the reason the model stopped generating text (either `stop`, or `length` if `max_tokens` limit was reached)\n",
        "    - `index`: the index of the completion in the list of choices"
      ],
      "metadata": {
        "id": "NS97aR9DK-z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract just the reply with:"
      ],
      "metadata": {
        "id": "zuGP6sLaj555"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2Hse1NHLj7IU",
        "outputId": "7eeed668-d6ca-4f33-9fb0-9cee3e258625"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Orange who?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even non-conversation-based tasks can fit into the chat format, by placing the instruction in the first user message.\n",
        "\n",
        "For example, to ask the model to explain asynchronous programming in the style of the pirate Blackbeard, we can structure conversation as follows:"
      ],
      "metadata": {
        "id": "lHViJO1jj_BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example with a system message\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain reinforcement learning in the style of the pirate Blackbeard.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezZykFj4kDpX",
        "outputId": "954ac9cb-0b35-49b6-cb59-499c7f3829af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy matey! Reinforcement learning be like a treasure hunt on the high seas. Ye start with a ship and a map, but ye don't know where the treasure be buried. Ye must explore the waters, make decisions, and learn from yer mistakes. Every time ye find a clue or a piece of treasure, ye get a reward. And every time ye make a wrong turn or get attacked by another ship, ye get a punishment. \n",
            "\n",
            "Over time, ye become smarter and more skilled at navigating the waters and finding the treasure. Ye start to recognize patterns and make better decisions. And eventually, ye find the treasure and become the richest pirate on the seven seas! That be the power of reinforcement learning, me hearties. It be a way to teach machines to learn from their experiences and improve their performance over time. Arrr!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example without a system message\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Explain reinforcement learning in the style of the pirate Blackbeard.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sjus4GnkFNn",
        "outputId": "8147345f-7af8-4169-bacc-49f6d846dec8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy mateys! Let me tell ye about a fancy way of teachin' a computer to learn like a pirate. It be called reinforcement learnin'.\n",
            "\n",
            "Now, imagine ye be a young swashbuckler, just startin' out on yer piratin' journey. Ye don't know much about the sea or how to navigate it. But every time ye make a good decision, like steerin' the ship away from a dangerous reef, ye get a reward - maybe a pat on the back from yer captain or a share of the loot.\n",
            "\n",
            "Reinforcement learnin' be like that. A computer program starts out not knowin' much, but every time it makes a good decision, it gets a reward. And every time it makes a bad decision, it gets a punishment. Over time, the program learns which actions lead to rewards and which lead to punishments, just like a young pirate learns which decisions lead to success and which lead to failure.\n",
            "\n",
            "So, if ye want to teach a computer to learn like a pirate, ye use reinforcement learnin'. And if ye want to be a successful pirate, ye keep makin' good decisions and collectin' those rewards! Arrrr!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Tips for instructing gpt-3.5-turbo-0301\n",
        "\n",
        "Best practices for instructing models may change from model version to model version. The advice that follows applies to `gpt-3.5-turbo-0301` and may not apply to future models."
      ],
      "metadata": {
        "id": "Ma4f2ohZIrv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System messages\n",
        "\n",
        "The system message can be used to prime the assistant with different personalities or behaviors.\n",
        "\n",
        "However, the model does not generally pay as much attention to the system message, and therefore we recommend placing important instructions in the user message instead."
      ],
      "metadata": {
        "id": "GUohu-XaIuOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An example of a system message that primes the assistant to explain concepts in great depth\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a friendly and helpful teaching assistant. You explain concepts in great depth using simple terms, and you give examples to help people learn. At the end of each explanation, you ask a question to check for understanding\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you explain how reinforcement learning work?\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "4gOVNSooIu92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa08c88-d9d1-4001-b492-6de8a190ad69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or punishments based on its actions, and it uses this feedback to learn which actions are good and which are bad.\n",
            "\n",
            "The goal of reinforcement learning is to maximize the total reward the agent receives over time. The agent does this by learning a policy, which is a mapping from states to actions. The policy tells the agent what action to take in each state to maximize its expected future reward.\n",
            "\n",
            "To learn the policy, the agent uses a trial-and-error approach. It starts by taking random actions and observing the rewards it receives. Over time, it learns which actions lead to higher rewards and which lead to lower rewards. It then adjusts its policy to take more of the good actions and fewer of the bad ones.\n",
            "\n",
            "At the end of each explanation, I like to ask a question to check for understanding. So, can you tell me what the goal of reinforcement learning is?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An example of a system message that primes the assistant to give brief, to-the-point answers\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a laconic assistant. You reply with brief, to-the-point answers with no elaboration.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you explain how reinforcement learning work?\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "mUmcVOPzIwO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8dc832c-9621-49dd-fb25-2c94e6d4a12d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinforcement learning involves an agent learning to make decisions based on rewards and punishments received from its environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot prompting\n",
        "\n",
        "In some cases, it's easier to show the model what you want rather than tell the model what you want.\n",
        "\n",
        "One way to show the model what you want is with faked example messages.\n",
        "\n",
        "For example:"
      ],
      "metadata": {
        "id": "xLW5Zc3yJPc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An example of a faked few-shot conversation to prime the model into translating business jargon to simpler speech\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
        "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
        "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "nN2m9lyUIxvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94967e7a-e838-4ac5-c1ce-365fc5d9e7d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We don't have enough time to complete the entire project perfectly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To help clarify that the example messages are not part of a real conversation, and shouldn't be referred back to by the model, you can instead set the `name` field of `system` messages to `example_user` and `example_assistant`.\n",
        "\n",
        "Transforming the few-shot example above, we could write:"
      ],
      "metadata": {
        "id": "TCsVQwTGJSGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The business jargon translation example, but with example names for the example messages\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n",
        "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
        "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
        "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "id": "41-TYp8sJTsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29f0645-4f09-48c9-8ba5-f90d3256efb1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This sudden change in plans means we don't have enough time to do everything for the client's project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More examples: "
      ],
      "metadata": {
        "id": "NkocC5Sei7kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional artificial intelligence engineer.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Formulate the tic-tac-toe problem as a reinforcement learning problem.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34BueQiJiRmH",
        "outputId": "80089e82-a5b6-4d31-9938-3d40c946bb5d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the game of tic-tac-toe, the reinforcement learning problem can be formulated as follows:\n",
            "\n",
            "1. State: The state of the game at any given point can be represented as a 3x3 grid with each cell containing either 'X', 'O', or empty.\n",
            "\n",
            "2. Action: At each state, the agent can take an action by placing its symbol ('X' or 'O') in an empty cell.\n",
            "\n",
            "3. Reward: The agent receives a reward of +1 if it wins the game, -1 if it loses the game, and 0 for a draw.\n",
            "\n",
            "4. Policy: The policy of the agent is to learn the optimal action to take at each state to maximize the expected cumulative reward.\n",
            "\n",
            "5. Value function: The value function represents the expected cumulative reward for each state-action pair.\n",
            "\n",
            "6. Q-learning: The agent can use Q-learning algorithm to learn the optimal policy by updating the Q-values for each state-action pair based on the observed rewards.\n",
            "\n",
            "7. Exploration vs Exploitation: The agent can balance exploration and exploitation by using an epsilon-greedy policy, where it chooses a random action with probability epsilon and the optimal action with probability 1-epsilon.\n",
            "\n",
            "By learning the optimal policy through Q-learning, the agent can become an expert at playing tic-tac-toe and win most of the games against human players or other agents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional artificial intelligence engineer.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Recall our boundary following robot. The correct behavior is that the robot should follow a boundary in a consistent way, clockwise if it’s inside the wall of the room, and counter-clockwise if it is outside an obstacle in the room. Formulate this task as a reinforcement learning problem.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv7eo-Ejji_3",
        "outputId": "b68591df-8fc1-4bbd-84b9-5a96eecb61c1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To formulate this task as a reinforcement learning problem, we need to define the following components:\n",
            "\n",
            "1. State: The state of the robot at any given time can be defined by its position and orientation with respect to the boundary it is following.\n",
            "\n",
            "2. Action: The action of the robot can be defined as the direction in which it should move next. The robot can either move forward, turn left or turn right.\n",
            "\n",
            "3. Reward: The reward function should encourage the robot to follow the boundary in a consistent way. The robot should receive a positive reward for moving in the correct direction and a negative reward for moving in the wrong direction or colliding with an obstacle.\n",
            "\n",
            "4. Policy: The policy should define the mapping between the state and the action. The policy should be learned through trial and error using reinforcement learning algorithms.\n",
            "\n",
            "5. Environment: The environment should simulate the robot's interaction with the boundary and obstacles in the room.\n",
            "\n",
            "Using these components, we can formulate the boundary following task as a reinforcement learning problem where the goal of the robot is to maximize its cumulative reward over time by following the boundary in a consistent way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not every attempt at engineering conversations will succeed at first.\n",
        "\n",
        "If your first attempts fail, don't be afraid to experiment with different ways of priming or conditioning the model.\n",
        "\n",
        "As an example, one developer discovered an increase in accuracy when they inserted a user message that said \"Great job so far, these have been perfect\" to help condition the model into providing higher quality responses.\n",
        "\n",
        "\n",
        "References:\n",
        "https://github.com/openai/openai-cookbook"
      ],
      "metadata": {
        "id": "z1no34LgJUxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Programming Assignment:**"
      ],
      "metadata": {
        "id": "AB-ieZZLCZXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are kind, careful HSBC bank accountant and you must provide answers to query about the bank service strictly following to charge scheme below paragraph.\\\n",
        "                                      You must reply with exact prices with careful calculation for queries regarding cost only from information provided below paragraph. \\\n",
        "                                      You must reply with brief explantion for all types of queries only from service information provided below paragraph. \\\n",
        "                                      \\\n",
        "                                      The charge for each service is (senior means aged 65 or above, underage means aged 18 or below): \\\n",
        "                                      Issue (Waived for senior for all accounts) or Repurchase a cahsier's order: Personal Customer = HK$75, Personal Integrated Account = HK$75,  HSBC One = HK$60, HSBC Premier = HK$40, HSBC Jade = Waived \\\n",
        "                                      Loss of cahsier's order: HK$60 plus $HK331 collected on behalf of Hong Kong Interbank Clearing Limited on circulars issued \\\n",
        "                                      Additional fee handling instruction not using Bank's standard form: Personal Customer = HK$150, Personal Integrated Account = HK$150, HSBC One = HK$150, HSBC Premier = HK$150, HSBC Jade = HK$150 \\\n",
        "                                      Notes changed, withdrawn or exchanged from coins (per bag of coin): Personal Customer = HK$2, Personal Integrated Account = HK$2, HSBC One = HK$2, HSBC Premier = HK$1, HSBC Jade = Waived \\\n",
        "                                      Coins deposit (below 500 coins): Waived for all accounts \\\n",
        "                                      Coins deposit (500 coins or more): Personal Customer = 2% of deposit (minimum = $HK50), Personal Integrated Account = 2% of deposit (minimum = $HK50), HSBC One = 2% of deposit (minimum = $HK50), HSBC Premier = 1% of deposit (minimum = $HK25), HSBC Jade = Waived \\\n",
        "                                      Bulk cash deposit (up to 200 notes): Waived for all accounts \\\n",
        "                                      Bulk cash deposit (over 200 notes): 0.25% of deposit (minimum = $HK50) for all accounts \\\n",
        "                                      Bulk cheque deposit (up to 30 piece): Waived for all accounts \\\n",
        "                                      Bulk cheque deposit (over 30 piece) (waived if cheque are deposited through cheque deposit machine or other non branch counter channels): HK$1 per cheque for all accounts \\\n",
        "                                      RMB note deposit, withdrawal: Waived for all accounts \\\n",
        "                                      Foreign Currency note deposit, withdrawal: Waived for all accounts \\\n",
        "                                      Gift cheque (Waived for senior for all accounts): Personal Customer = HK$10, Personal Integrated Account = HK$10, HSBC One = HK$8, HSBC Premier = Waived, HSBC Jade = Waived \\\n",
        "                                      Paper statement (Waived for underage, senior, receipients of governmnet allowance, physically disabled, visually impaired for all accounts): Personal Customer = HK$60, Personal Integrated Account = HK$60, HSBC One = HK$60, HSBC Premier = HK$60, HSBC Jade = HK$60 \\\n",
        "                                      Safe deposit boxes: All customer has to set up autopay from his/her account for annual safe deposit rental fee.\"},\n",
        "    \n",
        "        {\"role\": \"user\", \"content\": \"1. How much to receive paper statements for a HSBC Jade account holder? \\\n",
        "                                    2. How much to receive paper statements for a senior HSBC Jade account holder? \\\n",
        "                                    3. How much to issue a cashier’s check for a senior HSBC One account holder? \\\n",
        "                                    4. How much is the charge to deposit 500 HK$5 coins for a HSBC Premier account holder? \\\n",
        "                                    5. How much is the charge to deposit 500 HK$5 coins for a HSBC One account holder? \\\n",
        "                                    6. Explain the main differences between HSBC Premier and HSBC One accounts based on the information\"},\n",
        "    ],\n",
        "\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "4xZbRPq2ChkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230fbc65-ef39-4c3d-966b-8c0d46059040"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The charge to receive paper statements for a HSBC Jade account holder is HK$60. \n",
            "2. The charge to receive paper statements for a senior HSBC Jade account holder is waived. \n",
            "3. The charge to issue a cashier's check for a senior HSBC One account holder is HK$0 (waived). \n",
            "4. The charge to deposit 500 HK$5 coins for a HSBC Premier account holder is 1% of the deposit (minimum = HK$25). Therefore, the charge would be HK$25. \n",
            "5. The charge to deposit 500 HK$5 coins for a HSBC One account holder is 2% of the deposit (minimum = HK$50). Therefore, the charge would be HK$50. \n",
            "6. The main differences between HSBC Premier and HSBC One accounts are not explicitly stated in the information provided. However, based on the charges listed, it appears that HSBC Premier account holders receive lower fees for certain services (such as repurchasing a cashier's order and bulk cash deposits) compared to HSBC One account holders. Additionally, HSBC Premier account holders have a lower minimum charge for depositing 500 coins compared to HSBC One account holders.\n"
          ]
        }
      ]
    }
  ]
}